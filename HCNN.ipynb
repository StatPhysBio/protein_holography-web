{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPah+rXZyqiCgmjBQFlpxxW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StatPhysBio/protein_holography-web/blob/main/HCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b>Install condacolab\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    !pip install condacolab\n",
        "    import condacolab\n",
        "    condacolab.install()\n",
        "except ModuleNotFoundError:\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "sgb5ws5ltcff",
        "outputId": "371fa394-f0b7-42a8-c142-71131a4796f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting condacolab\n",
            "  Downloading condacolab-0.1.9-py3-none-any.whl.metadata (5.6 kB)\n",
            "Downloading condacolab-0.1.9-py3-none-any.whl (7.2 kB)\n",
            "Installing collected packages: condacolab\n",
            "Successfully installed condacolab-0.1.9\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m‚ú®üç∞‚ú® Everything looks OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b>Download repository, models and setup environment\n",
        "\n",
        "#@markdown If prompted to restart the runtime due to some packages being already installed, simply restart and re-run the cells above and including this one. The conflict should resolve itself after 1 or 2 restarting prompts. We are currently working on making that not happen.\n",
        "\n",
        "! rm -r sample_data\n",
        "\n",
        "! pip install torch==1.13.1\n",
        "! conda install -c conda-forge openmm==8.0.0\n",
        "! conda install -c conda-forge pdbfixer==1.9\n",
        "! pip install pandas==1.5.0\n",
        "! pip install e3nn==0.5.0\n",
        "\n",
        "! git clone https://github.com/StatPhysBio/protein_holography-web.git\n",
        "%cd protein_holography-web\n",
        "! git clone https://github.com/StatPhysBio/zernikegrams.git\n",
        "%cd zernikegrams\n",
        "! pip install .\n",
        "%cd ..\n",
        "! pip install .\n",
        "%cd ..\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pfOyfkx_tvBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b03c2ef3-4c3d-4e68-8f5d-2c123d2ad548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'sample_data': No such file or directory\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.10/site-packages (1.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/site-packages (from torch==1.13.1) (4.12.2)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/site-packages (from torch==1.13.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/site-packages (from torch==1.13.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/site-packages (from torch==1.13.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/site-packages (from torch==1.13.1) (11.7.99)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (68.2.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (0.42.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mChannels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 23.11.0\n",
            "    latest version: 24.5.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "# All requested packages already installed.\n",
            "\n",
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 23.11.0\n",
            "    latest version: 24.5.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "# All requested packages already installed.\n",
            "\n",
            "Requirement already satisfied: pandas==1.5.0 in /usr/local/lib/python3.10/site-packages (1.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/site-packages (from pandas==1.5.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas==1.5.0) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/site-packages (from pandas==1.5.0) (1.26.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas==1.5.0) (1.16.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting e3nn==0.5.0\n",
            "  Using cached e3nn-0.5.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting sympy (from e3nn==0.5.0)\n",
            "  Using cached sympy-1.12.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting scipy (from e3nn==0.5.0)\n",
            "  Using cached scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/site-packages (from e3nn==0.5.0) (1.13.1)\n",
            "Collecting opt-einsum-fx>=0.1.4 (from e3nn==0.5.0)\n",
            "  Using cached opt_einsum_fx-0.1.4-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting opt-einsum (from opt-einsum-fx>=0.1.4->e3nn==0.5.0)\n",
            "  Using cached opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from opt-einsum-fx>=0.1.4->e3nn==0.5.0) (23.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->e3nn==0.5.0) (4.12.2)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->e3nn==0.5.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->e3nn==0.5.0) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->e3nn==0.5.0) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/site-packages (from torch>=1.8.0->e3nn==0.5.0) (11.7.99)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8.0->e3nn==0.5.0) (68.2.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8.0->e3nn==0.5.0) (0.42.0)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/site-packages (from scipy->e3nn==0.5.0) (1.26.4)\n",
            "Collecting mpmath<1.4.0,>=1.1.0 (from sympy->e3nn==0.5.0)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Using cached e3nn-0.5.0-py3-none-any.whl (117 kB)\n",
            "Using cached opt_einsum_fx-0.1.4-py3-none-any.whl (13 kB)\n",
            "Downloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.12.1-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mpmath, sympy, scipy, opt-einsum, opt-einsum-fx, e3nn\n",
            "Successfully installed e3nn-0.5.0 mpmath-1.3.0 opt-einsum-3.3.0 opt-einsum-fx-0.1.4 scipy-1.13.1 sympy-1.12.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mfatal: destination path 'protein_holography-web' already exists and is not an empty directory.\n",
            "/content/protein_holography-web\n",
            "Cloning into 'zernikegrams'...\n",
            "remote: Enumerating objects: 778, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 778 (delta 0), reused 3 (delta 0), pack-reused 763\u001b[K\n",
            "Receiving objects: 100% (778/778), 52.20 MiB | 28.81 MiB/s, done.\n",
            "Resolving deltas: 100% (421/421), done.\n",
            "/content/protein_holography-web/zernikegrams\n",
            "Processing /content/protein_holography-web/zernikegrams\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting argparse (from zernikegrams==0.1.0)\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting biopython (from zernikegrams==0.1.0)\n",
            "  Downloading biopython-1.83-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting cmake (from zernikegrams==0.1.0)\n",
            "  Downloading cmake-3.29.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting h5py (from zernikegrams==0.1.0)\n",
            "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting hdf5plugin (from zernikegrams==0.1.0)\n",
            "  Downloading hdf5plugin-4.4.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/site-packages (from zernikegrams==0.1.0) (1.26.4)\n",
            "Collecting pyopencl (from zernikegrams==0.1.0)\n",
            "  Downloading pyopencl-2024.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Collecting pytest (from zernikegrams==0.1.0)\n",
            "  Downloading pytest-8.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/site-packages (from zernikegrams==0.1.0) (1.13.1)\n",
            "Collecting rich (from zernikegrams==0.1.0)\n",
            "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting scikit-learn (from zernikegrams==0.1.0)\n",
            "  Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting sqlitedict (from zernikegrams==0.1.0)\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting stopit (from zernikegrams==0.1.0)\n",
            "  Downloading stopit-1.1.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyyaml (from zernikegrams==0.1.0)\n",
            "  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/site-packages (from pyopencl->zernikegrams==0.1.0) (4.1.0)\n",
            "Collecting pytools>=2024.1.5 (from pyopencl->zernikegrams==0.1.0)\n",
            "  Downloading pytools-2024.1.5-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting iniconfig (from pytest->zernikegrams==0.1.0)\n",
            "  Downloading iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from pytest->zernikegrams==0.1.0) (23.2)\n",
            "Collecting pluggy<2.0,>=1.5 (from pytest->zernikegrams==0.1.0)\n",
            "  Downloading pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting exceptiongroup>=1.0.0rc8 (from pytest->zernikegrams==0.1.0)\n",
            "  Downloading exceptiongroup-1.2.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting tomli>=1 (from pytest->zernikegrams==0.1.0)\n",
            "  Using cached tomli-2.0.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->zernikegrams==0.1.0)\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich->zernikegrams==0.1.0)\n",
            "  Downloading pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn->zernikegrams==0.1.0) (1.13.1)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn->zernikegrams==0.1.0)\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn->zernikegrams==0.1.0)\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/site-packages (from torch->zernikegrams==0.1.0) (4.12.2)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/site-packages (from torch->zernikegrams==0.1.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/site-packages (from torch->zernikegrams==0.1.0) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/site-packages (from torch->zernikegrams==0.1.0) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/site-packages (from torch->zernikegrams==0.1.0) (11.7.99)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->zernikegrams==0.1.0) (68.2.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->zernikegrams==0.1.0) (0.42.0)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->zernikegrams==0.1.0)\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Downloading biopython-1.83-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cmake-3.29.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hdf5plugin-4.4.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m41.8/41.8 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyopencl-2024.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (697 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m698.0/698.0 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest-8.2.2-py3-none-any.whl (339 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m339.9/339.9 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m705.5/705.5 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading exceptiongroup-1.2.1-py3-none-any.whl (16 kB)\n",
            "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
            "Downloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytools-2024.1.5-py2.py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m88.1/88.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Using cached tomli-2.0.1-py3-none-any.whl (12 kB)\n",
            "Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
            "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Building wheels for collected packages: zernikegrams, sqlitedict, stopit\n",
            "  Building wheel for zernikegrams (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for zernikegrams: filename=zernikegrams-0.1.0-py3-none-any.whl size=14388134 sha256=5dc2d06db946dad3087157612573f403036ac826049385dad054014f6588c6cf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wskv08em/wheels/73/8b/53/ecb361d9388f92533d16e2ada24afe945bd22de3634accb71a\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16863 sha256=32ec377bca80becf611b90e0e988516442f7f278bb238c3b87476be95ad14f63\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
            "  Building wheel for stopit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stopit: filename=stopit-1.1.2-py3-none-any.whl size=11937 sha256=e5a515792be1f84e71c487dd24c7599001c08e097317b2b3cd7b7bddffac34e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/f9/87/bf5b3d565c2a007b4dae9d8142dccc85a9f164e517062dd519\n",
            "Successfully built zernikegrams sqlitedict stopit\n",
            "Installing collected packages: stopit, sqlitedict, argparse, tomli, threadpoolctl, pyyaml, pytools, pygments, pluggy, mdurl, joblib, iniconfig, h5py, exceptiongroup, cmake, biopython, scikit-learn, pytest, pyopencl, markdown-it-py, hdf5plugin, rich, zernikegrams\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 1.3.0\n",
            "    Uninstalling pluggy-1.3.0:\n",
            "      Successfully uninstalled pluggy-1.3.0\n",
            "Successfully installed argparse-1.4.0 biopython-1.83 cmake-3.29.5 exceptiongroup-1.2.1 h5py-3.11.0 hdf5plugin-4.4.0 iniconfig-2.0.0 joblib-1.4.2 markdown-it-py-3.0.0 mdurl-0.1.2 pluggy-1.5.0 pygments-2.18.0 pyopencl-2024.2.6 pytest-8.2.2 pytools-2024.1.5 pyyaml-6.0.1 rich-13.7.1 scikit-learn-1.5.0 sqlitedict-2.1.0 stopit-1.1.2 threadpoolctl-3.5.0 tomli-2.0.1 zernikegrams-0.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m/content/protein_holography-web\n",
            "Processing /content/protein_holography-web\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: protein-holography-web\n",
            "  Building wheel for protein-holography-web (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for protein-holography-web: filename=protein_holography_web-0.1.0-py3-none-any.whl size=3778 sha256=620ee54a54c0120e4ea14b55c0677892ccb206a646c804a3be632505ac74b7de\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/1f/0a/8d64a928044d97e5c62f680be31cbffbff1d88e8e480a60cab\n",
            "Successfully built protein-holography-web\n",
            "Installing collected packages: protein-holography-web\n",
            "Successfully installed protein-holography-web-0.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b>Single PDB request</b>\n",
        "\n",
        "#@markdown Choose between <b>ONE</font></b> of the possible input sources for the target pdb.\n",
        "#@markdown - AlphaFold2 PDB (v4) via Uniprot ID:\n",
        "AF_ID =''#@param {type:\"string\"}\n",
        "#@markdown - PDB ID (imported from RCSB PDB):\n",
        "PDB_ID ='1AO7'#@param {type:\"string\"}\n",
        "#@markdown - Specify path to pdb\n",
        "PDB_PATH ='' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Select target chain. Default is \"all\" which computes all chains. Note that we do not remove the other chains from the PDB file.\n",
        "CHAIN_ID='B' #@param {type:'string'}\n",
        "\n",
        "\n",
        "\n",
        "# download pdbs\n",
        "import os\n",
        "\n",
        "TEMP_PDB_DIR = \"/content/pdb_dir/\"\n",
        "TEMP_PDB_AND_CHAIN_FILE = '/content/pdbs_and_chains.txt'\n",
        "\n",
        "if os.path.exists(TEMP_PDB_DIR):\n",
        "    os.system(f'rm -r {TEMP_PDB_DIR}')\n",
        "os.makedirs(TEMP_PDB_DIR)\n",
        "\n",
        "if os.path.exists(TEMP_PDB_AND_CHAIN_FILE):\n",
        "    os.system(f'rm {TEMP_PDB_AND_CHAIN_FILE}')\n",
        "\n",
        "\n",
        "class TooManyInputsError(Exception):\n",
        "    pass\n",
        "\n",
        "if PDB_PATH != '':\n",
        "    if AF_ID != '' or PDB_ID != '': raise TooManyInputsError('Please specify only one between AF_ID, PDB_ID, and PDB_PATH')\n",
        "    os.system(f\"cp {PDB_PATH} {TEMP_PDB_DIR}\")\n",
        "    filename = '.'.join(os.basename(PDB_PATH).split('.')[:-1])\n",
        "\n",
        "elif AF_ID !='':\n",
        "    if len(AF_ID) < 6: raise ValueError(\"AF_ID must have length at least 6 since it's a uniprot ID\")\n",
        "    if PDB_PATH != '' or PDB_ID != '': raise TooManyInputsError('Please pecify only one between AF_ID, PDB_ID, and PDB_PATH')\n",
        "    os.system(f'curl -s -f https://alphafold.ebi.ac.uk/files/AF-{AF_ID}-F1-model_v4.pdb -o {os.path.join(TEMP_PDB_DIR, f\"AF-{AF_ID}-F1-model_v4.pdb\")}')\n",
        "    filename = f'AF-{AF_ID}-F1-model_v4'\n",
        "\n",
        "elif PDB_ID !='':\n",
        "    if len(PDB_ID) != 4: raise ValueError(\"PDB_ID must have length 4 to be valid.\")\n",
        "    if PDB_PATH != '' or AF_ID != '': raise TooManyInputsError('Please pecify only one between AF_ID, PDB_ID, and PDB_PATH')\n",
        "    os.system(f'curl -s -f https://files.rcsb.org/download/{PDB_ID}.pdb -o {os.path.join(TEMP_PDB_DIR, f\"{PDB_ID}.pdb\")}')\n",
        "    filename = PDB_ID\n",
        "\n",
        "else:\n",
        "    raise ValueError('Please specify one of the above inputs.')\n",
        "\n",
        "if len(CHAIN_ID) > 1 and CHAIN_ID != 'all':\n",
        "    raise ValueError(f'CHAIN_ID must be a single characher, cannot be \"{CHAIN_ID}\"')\n",
        "\n",
        "\n",
        "with open(TEMP_PDB_AND_CHAIN_FILE, 'w+') as f:\n",
        "    f.write(filename)\n",
        "    if CHAIN_ID != 'all':\n",
        "        f.write(' ' + CHAIN_ID)\n",
        "\n"
      ],
      "metadata": {
        "id": "6tDkKC3-XTzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b>Multiple PDBs request</b>\n",
        "\n",
        "## TODO"
      ],
      "metadata": {
        "id": "E8A8BJQIhs27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "iJm0k2OsSs44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9175cf0c-a943-46ed-bc82-ca9017ffb6e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <b>Run selected model with desired outputs</font></b>\n",
        "\n",
        "#@markdown <b>Choose one and only one model version<b>\n",
        "HCNN_biopython_proteinnet_0p00=True#@param {type:\"boolean\"}\n",
        "HCNN_biopython_proteinnet_0p50=False#@param {type:\"boolean\"}\n",
        "HCNN_biopython_proteinnet_extra_mols_0p00=False#@param {type:\"boolean\"}\n",
        "HCNN_biopython_proteinnet_extra_mols_0p50=False#@param {type:\"boolean\"}\n",
        "\n",
        "if HCNN_biopython_proteinnet_0p00:\n",
        "    if HCNN_biopython_proteinnet_0p50 or HCNN_biopython_proteinnet_extra_mols_0p00 or HCNN_biopython_proteinnet_extra_mols_0p50: raise ValueError(\"Please select one and only one model.\")\n",
        "    MODEL_VERSION = \"HCNN_biopython_proteinnet_0p00\"\n",
        "elif HCNN_biopython_proteinnet_0p50:\n",
        "    if HCNN_biopython_proteinnet_0p00 or HCNN_biopython_proteinnet_extra_mols_0p00 or HCNN_biopython_proteinnet_extra_mols_0p50: raise ValueError(\"Please select one and only one model.\")\n",
        "    MODEL_VERSION = \"HCNN_biopython_proteinnet_0p50\"\n",
        "elif HCNN_biopython_proteinnet_extra_mols_0p00:\n",
        "    if HCNN_biopython_proteinnet_0p00 or HCNN_biopython_proteinnet_0p50 or HCNN_biopython_proteinnet_extra_mols_0p50: raise ValueError(\"Please select one and only one model.\")\n",
        "    MODEL_VERSION = \"HCNN_biopython_proteinnet_extra_mols_0p00\"\n",
        "elif HCNN_biopython_proteinnet_extra_mols_0p50:\n",
        "    if HCNN_biopython_proteinnet_0p00 or HCNN_biopython_proteinnet_0p50 or HCNN_biopython_proteinnet_extra_mols_0p00: raise ValueError(\"Please select one and only one model.\")\n",
        "    MODEL_VERSION = \"HCNN_biopython_proteinnet_extra_mols_0p50\"\n",
        "else:\n",
        "    raise ValueError(\"Please select one and only one model.\")\n",
        "\n",
        "#@markdown The first two models exclude extra ligands and ions in the PDB files.\n",
        "#@markdown The other two keep them. All models remove waters. \\\n",
        "#@markdown \"_0p00\" and \"_0p50\" denote the amount of noise - in Angstrom - with which the models were trained.\n",
        "\n",
        "#@markdown\n",
        "\n",
        "#@markdown <b>Choose desired outputs<b>\n",
        "probas=True#@param {type:\"boolean\"}\n",
        "logprobas=False#@param {type:\"boolean\"}\n",
        "logits=False#@param {type:\"boolean\"}\n",
        "embeddings=False#@param {type:\"boolean\"}\n",
        "\n",
        "REQUEST_STRING = ''\n",
        "if probas: REQUEST_STRING += ' probas'\n",
        "if logprobas: REQUEST_STRING += ' logprobas'\n",
        "if logits: REQUEST_STRING += ' logits'\n",
        "if embeddings: REQUEST_STRING += ' embeddings'\n",
        "REQUEST_STRING = REQUEST_STRING.strip()\n",
        "\n",
        "#@markdown Probas, logprobas and/or logits will be saved in file `output_{MODEL_VERSION}.csv`. \\\n",
        "#@markdown Embeddings will be saved in file `output_{MODEL_VERSION}-embeddings.npy`.\n",
        "\n",
        "\n",
        "os.system(f\"python protein_holography-web/run_hcnn_on_pdbfiles.py \\\n",
        "            -m {MODEL_VERSION} \\\n",
        "            -pd {TEMP_PDB_DIR} \\\n",
        "            -pn {TEMP_PDB_AND_CHAIN_FILE} \\\n",
        "            -o output_{MODEL_VERSION}.csv \\\n",
        "            -v 0 \\\n",
        "            -lb 1 \\\n",
        "            -r {REQUEST_STRING}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "MC77V8YR9hmV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f68ce960-3fd4-43ad-9912-5d28f3f65138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}